---
phase: 07-cold-start-launch-hardening
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - api/scripts/generate_capacity_data.py
  - tests/load/locustfile_capacity.py
  - tests/load/locustfile_rate_limit.py
  - docker-compose.capacity.yml
autonomous: true

must_haves:
  truths:
    - "pgvector HNSW search delivers under 50ms p99 latency at 100K traces — measured by Locust CSV output"
    - "Token-bucket rate limiter allows a burst of requests up to the bucket capacity without incorrectly blocking"
    - "After bucket exhaustion, subsequent requests receive 429 with Retry-After header"
    - "After partial wait, refilled tokens allow proportional new requests (token-bucket refill validation)"
    - "Different users get independent rate limit buckets (no cross-user interference)"
  artifacts:
    - path: "api/scripts/generate_capacity_data.py"
      provides: "Script to populate 100K synthetic traces with embeddings directly into database"
      contains: "100_000"
    - path: "tests/load/locustfile_capacity.py"
      provides: "Locust load test measuring HNSW search p99 latency at 100K scale"
      contains: "SearchLoadUser"
    - path: "tests/load/locustfile_rate_limit.py"
      provides: "Locust burst test validating token-bucket rate limiter behavior"
      contains: "BurstAgent"
    - path: "docker-compose.capacity.yml"
      provides: "Docker Compose override with tuned PostgreSQL memory settings for 100K HNSW"
      contains: "shared_buffers"
  key_links:
    - from: "api/scripts/generate_capacity_data.py"
      to: "docker-compose.yml (postgres)"
      via: "asyncpg direct connection for bulk insert with vector data"
      pattern: "asyncpg\\.connect"
    - from: "tests/load/locustfile_capacity.py"
      to: "api/app/routers/search.py"
      via: "POST /api/v1/traces/search endpoint with search query"
      pattern: "/api/v1/traces/search"
    - from: "tests/load/locustfile_rate_limit.py"
      to: "api/app/middleware/rate_limiter.py"
      via: "Exercises token-bucket Lua rate limiter via HTTP requests, expects 429 after exhaustion"
      pattern: "429"
---

<objective>
Validate system capacity at 100K traces and verify rate limiter behavior under realistic agent burst workloads using automated load testing.

Purpose: Before public launch, the system must prove it can handle scale (100K traces with sub-50ms p99 HNSW search latency) and that the rate limiter correctly handles bursty agent workloads without incorrectly blocking legitimate traffic. This plan provides the validation infrastructure and test scripts.

Output: Data generation script (`generate_capacity_data.py`), Locust load test files (`locustfile_capacity.py`, `locustfile_rate_limit.py`), and a Docker Compose override for capacity testing (`docker-compose.capacity.yml`).
</objective>

<execution_context>
@/home/bitnami/.claude/get-shit-done/workflows/execute-plan.md
@/home/bitnami/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-cold-start-launch-hardening/07-RESEARCH.md
@api/app/config.py
@api/app/middleware/rate_limiter.py
@api/app/routers/search.py
@docker-compose.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create capacity test infrastructure (data generator + Compose override)</name>
  <files>api/scripts/generate_capacity_data.py, docker-compose.capacity.yml</files>
  <action>
**Part A: Create `docker-compose.capacity.yml`**

A Docker Compose override file that tunes PostgreSQL for HNSW capacity testing at 100K traces. Used with: `docker compose -f docker-compose.yml -f docker-compose.capacity.yml up`.

```yaml
# Override postgres service with tuned memory settings for 100K HNSW
services:
  postgres:
    command: >
      postgres
      -c shared_buffers=2GB
      -c effective_cache_size=4GB
      -c maintenance_work_mem=1GB
      -c work_mem=64MB
```

At 100K 1536-dim vectors, the HNSW index is ~600MB. `shared_buffers=2GB` ensures the index fits in shared memory. `maintenance_work_mem=1GB` allows in-memory HNSW index builds.

**Part B: Create `api/scripts/generate_capacity_data.py`**

A standalone script that populates 100K synthetic traces with pre-computed embeddings directly into the database using asyncpg (not ORM — bulk performance).

**Key design:**
- Do NOT use OpenAI API — use random normalized vectors (numpy). This avoids $1.20+ in API costs and rate limiting delays. Random normalized vectors are sufficient for HNSW latency benchmarking (tests index traversal mechanics, not semantic quality).
- Use asyncpg `executemany` for bulk insert in batches of 1000 rows
- Create a dedicated capacity test user: `capacity-test@commontrace.internal`
- All traces: `is_seed=True`, `status='validated'`, `trust_score=1.0`, `confirmation_count=2`, `embedding_model_id='text-embedding-3-small'`
- Generate realistic-looking metadata using `faker` with `seed=42` for deterministic output
- Use numpy with `seed=42` for reproducible random vectors

**Algorithm for embedding generation (research recommendation: tiled vectors with noise):**
1. Generate 1000 base normalized random vectors (1536-dim)
2. For each of the 100K traces: pick `base_vectors[i % 1000]`, add small Gaussian noise (`sigma=0.05`), renormalize
3. This creates clusters of similar vectors — more realistic ANN search behavior than purely random vectors

**Script structure:**
```python
import asyncio, asyncpg, numpy as np, uuid
from faker import Faker

async def generate_capacity_data(database_url: str):
    # 1. Parse asyncpg URL from SQLAlchemy-style URL
    #    settings.database_url is "postgresql+asyncpg://..." — strip "+asyncpg"
    # 2. Connect via asyncpg
    # 3. Create capacity test user (ON CONFLICT DO NOTHING)
    # 4. Generate base vectors
    # 5. Batch insert 100K traces with embeddings in batches of 1000
    # 6. Print progress every 10K rows
    # 7. After insert, run REINDEX to rebuild HNSW index
    #    (the existing HNSW index from migration handles this automatically
    #     via PostgreSQL's aminsert path, but a REINDEX ensures optimal graph quality)
```

Add `__main__` block that reads DATABASE_URL from environment or app.config.settings.

**Install dev dependencies:** Add `locust` and `faker` to dev dependencies:
```bash
cd api && uv add --dev locust faker
```

Also create the `tests/load/` directory and an empty `__init__.py`.
  </action>
  <verify>
Run: `python3 -c "import ast; tree=ast.parse(open('api/scripts/generate_capacity_data.py').read()); print('OK')"` to verify syntax. Check: `grep -c '100_000\|asyncpg\|numpy\|faker' api/scripts/generate_capacity_data.py` should return 4+. Verify compose override: `docker compose -f docker-compose.yml -f docker-compose.capacity.yml config | grep shared_buffers`.
  </verify>
  <done>generate_capacity_data.py exists with asyncpg bulk insert of 100K traces using tiled random vectors; docker-compose.capacity.yml overrides postgres with 2GB shared_buffers and 1GB maintenance_work_mem</done>
</task>

<task type="auto">
  <name>Task 2: Create Locust load test files for capacity and rate limit validation</name>
  <files>tests/load/locustfile_capacity.py, tests/load/locustfile_rate_limit.py</files>
  <action>
**File 1: `tests/load/locustfile_capacity.py`** — HNSW p99 latency validation

Locust test that measures search endpoint latency at 100K trace scale.

```python
from locust import HttpUser, task, constant

SEARCH_QUERIES = [
    "react hooks useState",
    "postgresql migration alembic",
    "docker compose healthcheck",
    "fastapi async sqlalchemy",
    "python error handling retry",
    "github actions ci pipeline",
    "jwt authentication middleware",
    "redis caching ttl pattern",
    "typescript generics utility types",
    "pytest fixtures conftest setup",
]

class SearchLoadUser(HttpUser):
    wait_time = constant(0.1)  # 10 RPS per user

    def on_start(self):
        # Register a test user and get API key
        resp = self.client.post("/api/v1/keys", json={
            "email": f"load-{id(self)}@test.invalid"
        })
        key_data = resp.json()
        self.headers = {"X-API-Key": key_data["api_key"]}
        self._query_idx = 0

    @task
    def search(self):
        query = SEARCH_QUERIES[self._query_idx % len(SEARCH_QUERIES)]
        self._query_idx += 1
        self.client.post(
            "/api/v1/traces/search",
            json={"q": query, "limit": 10},
            headers=self.headers,
            name="/api/v1/traces/search"
        )
```

**Run command** (to be documented in script header):
```bash
# IMPORTANT: Set high rate limit for capacity testing — default 60/min causes 429s within 6 seconds per user
RATE_LIMIT_READ_PER_MINUTE=10000 locust -f tests/load/locustfile_capacity.py \
  --host http://localhost:8000 \
  --users 20 --spawn-rate 5 --run-time 60s \
  --headless --only-summary --csv=results/capacity
# Check p99: awk -F',' 'NR==2{print "p99:", $12, "ms"}' results/capacity_stats.csv
# Success criterion: p99 < 50ms
```

Note: The search endpoint latency includes the OpenAI embedding API call for the query vector. The p99 target of 50ms is for the HNSW ANN portion. For capacity testing, you can also measure raw HNSW latency via SQL EXPLAIN ANALYZE (see research doc). The Locust test measures end-to-end including embedding — if p99 exceeds 50ms, check whether the bottleneck is embedding API or HNSW by comparing against the SQL EXPLAIN ANALYZE times.

**File 2: `tests/load/locustfile_rate_limit.py`** — Token-bucket burst validation

Locust test that validates rate limiter behavior under agent-like burst patterns.

```python
from locust import HttpUser, task, constant, events
import time

class BurstAgent(HttpUser):
    """Simulates agent burst: rapid-fire requests to test token bucket behavior."""
    wait_time = constant(0)  # No wait — pure burst

    def on_start(self):
        resp = self.client.post("/api/v1/keys", json={
            "email": f"burst-{id(self)}@test.invalid"
        })
        key_data = resp.json()
        self.headers = {"X-API-Key": key_data["api_key"]}
        self.burst_count = 0
        self.success_count = 0
        self.rate_limited_count = 0

    @task
    def search_burst(self):
        with self.client.post(
            "/api/v1/traces/search",
            json={"q": "test query"},
            headers=self.headers,
            catch_response=True
        ) as resp:
            if resp.status_code == 200:
                self.success_count += 1
                resp.success()
            elif resp.status_code == 429:
                self.rate_limited_count += 1
                resp.success()  # 429 is EXPECTED — not a test failure
            else:
                resp.failure(f"Unexpected status {resp.status_code}")
        self.burst_count += 1


class RealisticAgent(HttpUser):
    """Simulates realistic agent pattern: 10-15 searches in 30s, then idle 5min."""
    wait_time = constant(2)  # ~2s between requests during active phase

    def on_start(self):
        resp = self.client.post("/api/v1/keys", json={
            "email": f"realistic-{id(self)}@test.invalid"
        })
        key_data = resp.json()
        self.headers = {"X-API-Key": key_data["api_key"]}
        self._request_count = 0

    @task
    def search_session(self):
        # Simulate 10-15 searches in quick succession
        if self._request_count < 15:
            self.client.post(
                "/api/v1/traces/search",
                json={"q": f"realistic query {self._request_count}"},
                headers=self.headers,
                name="/api/v1/traces/search [realistic]"
            )
            self._request_count += 1
        else:
            # Idle phase — simulate agent thinking/working
            time.sleep(30)
            self._request_count = 0
```

**Run command for burst test:**
```bash
locust -f tests/load/locustfile_rate_limit.py \
  --host http://localhost:8000 \
  --users 5 --spawn-rate 5 --run-time 30s \
  --headless --only-summary --csv=results/rate_limit
```

**Validation checklist (document in script header comments):**
1. BurstAgent: First `rate_limit_read_per_minute` (60) requests succeed, then 429s appear
2. BurstAgent: 429 responses include `Retry-After` header
3. RealisticAgent: 10-15 searches in 30s all succeed (bucket starts full at 60 tokens, uses 15 — well within limits)
4. Different users: Each BurstAgent gets its own independent bucket (verified by 5 concurrent users all succeeding initially)

**Auth note:** The load tests use `POST /api/v1/keys` to create API keys (this endpoint requires no auth per Phase 2 design). The returned `api_key` is used in the `X-API-Key` header. Check the actual endpoint response schema from Phase 2 — the field is `api_key` in the response JSON. If the key endpoint requires an email for RequireEmail, include the email field in the JSON body. Adjust the registration flow based on the actual API contract.
  </action>
  <verify>
Run: `python3 -c "import ast; ast.parse(open('tests/load/locustfile_capacity.py').read()); ast.parse(open('tests/load/locustfile_rate_limit.py').read()); print('Both files parse OK')"`. Check class names: `grep -c 'class SearchLoadUser\|class BurstAgent\|class RealisticAgent' tests/load/locustfile_capacity.py tests/load/locustfile_rate_limit.py`.
  </verify>
  <done>Two Locust load test files exist: locustfile_capacity.py (HNSW p99 measurement with 10 diverse search queries) and locustfile_rate_limit.py (burst validation with BurstAgent and RealisticAgent user classes); both are syntactically valid Python with documented run commands</done>
</task>

</tasks>

<verification>
1. `docker-compose.capacity.yml` overrides postgres with `shared_buffers=2GB`, `effective_cache_size=4GB`, `maintenance_work_mem=1GB`
2. `generate_capacity_data.py` inserts 100K traces with pre-computed 1536-dim normalized vectors using asyncpg bulk insert
3. `locustfile_capacity.py` exercises POST /api/v1/traces/search with diverse queries and reports p99 latency via Locust CSV
4. `locustfile_rate_limit.py` has both BurstAgent (pure burst, expects 429 after bucket exhaustion) and RealisticAgent (10-15 searches/30s, expects all succeed)
5. All Python files parse without syntax errors
6. Dev dependencies (locust, faker) are added to the project
</verification>

<success_criteria>
- Capacity test infrastructure is ready to run: `docker compose -f docker-compose.yml -f docker-compose.capacity.yml up` starts tuned postgres
- `python api/scripts/generate_capacity_data.py` populates 100K traces with embeddings in the database
- `locust -f tests/load/locustfile_capacity.py --headless` measures search p99 latency (target: <50ms HNSW portion)
- `locust -f tests/load/locustfile_rate_limit.py --headless` validates burst handling (60 successes then 429s for BurstAgent; all successes for RealisticAgent)
- Rate limiter correctly separates per-user buckets (verified by concurrent BurstAgent users)
</success_criteria>

<output>
After completion, create `.planning/phases/07-cold-start-launch-hardening/07-02-SUMMARY.md`
</output>
